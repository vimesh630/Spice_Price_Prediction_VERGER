{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed32cbae",
   "metadata": {},
   "source": [
    "# 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model # type: ignore\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU, SimpleRNN, BatchNormalization # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from itertools import product\n",
    "import optuna\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ceb618",
   "metadata": {},
   "source": [
    "# 2. Initialize Global Variables and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7636f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 12  # 12 months lookback\n",
    "MODEL_DIR = 'cinnamon_models'\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    print(f\"Created model directory: {MODEL_DIR}\")\n",
    "\n",
    "# Initialize preprocessors\n",
    "scaler_features = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "label_encoders = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0c6ac",
   "metadata": {},
   "source": [
    "# 3.Data Loading and Preparation Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(data_path):\n",
    "    \"\"\"Load and prepare the cinnamon price dataset\"\"\"\n",
    "    # Load data\n",
    "    print(f\"Loading data from {data_path}...\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Initial data shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Convert Month to datetime\n",
    "    df['Month'] = pd.to_datetime(df['Month'])\n",
    "\n",
    "    # Handle missing values in Regional_Price\n",
    "    missing_before = df['Regional_Price'].isna().sum()\n",
    "    df.loc[df['Is_Active_Region'] == 0, 'Regional_Price'] = df.loc[df['Is_Active_Region'] == 0, 'National_Price']\n",
    "    missing_after = df['Regional_Price'].isna().sum()\n",
    "    print(f\"Missing Regional_Price values: {missing_before} -> {missing_after}\")\n",
    "\n",
    "    # Encode categorical variables\n",
    "    for col in ['Grade', 'Region']:\n",
    "        if col not in label_encoders:\n",
    "            label_encoders[col] = LabelEncoder()\n",
    "        df[f'{col}_encoded'] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "    # Create additional time-based features\n",
    "    df['Year'] = df['Month'].dt.year\n",
    "    df['Month_num'] = df['Month'].dt.month\n",
    "    df['Quarter'] = df['Month'].dt.quarter\n",
    "\n",
    "    print(\"Creating lag and rolling features...\")\n",
    "\n",
    "    # Create lag features for key variables\n",
    "    df = df.sort_values(['Grade', 'Region', 'Month'])\n",
    "    lag_columns = ['Regional_Price', 'National_Price', 'Temperature', 'Rainfall']\n",
    "    for col in lag_columns:\n",
    "        if col in df.columns:\n",
    "            for lag in [1, 3, 6, 12]:\n",
    "                df[f'{col}_lag_{lag}'] = df.groupby(['Grade', 'Region'])[col].shift(lag)\n",
    "\n",
    "    # Create rolling averages\n",
    "    for col in ['Regional_Price', 'Temperature', 'Rainfall']:\n",
    "        if col in df.columns:\n",
    "            for window in [3, 6, 12]:\n",
    "                df[f'{col}_rolling_{window}'] = df.groupby(['Grade', 'Region'])[col].transform(\n",
    "                    lambda x: x.rolling(window).mean()\n",
    "                )\n",
    "\n",
    "    print(f\"Final data shape after feature engineering: {df.shape}\")\n",
    "    print(f\"Unique grades: {df['Grade'].unique()}\")\n",
    "    print(f\"Unique regions: {df['Region'].unique()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e67e87",
   "metadata": {},
   "source": [
    "# 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'C:/VERGER/Spice_Price_Prediction/Cinnamon/Datasets/Cinnamon_Dataset_New_0001_Filled.csv'\n",
    "\n",
    "df = load_and_prepare_data(DATA_PATH)\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810b62b",
   "metadata": {},
   "source": [
    "# 5. Visualization Function 1 - Price Distribution by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_distribution_by_grade(df):\n",
    "    \"\"\"Plot price distribution by grade\"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Remove rows with missing Regional_Price\n",
    "    df_clean = df.dropna(subset=['Regional_Price'])\n",
    "    \n",
    "    # Create subplots for different visualizations\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Box plot of prices by grade\n",
    "    sns.boxplot(data=df_clean, x='Grade', y='Regional_Price', ax=ax1)\n",
    "    ax1.set_title('Price Distribution by Grade (Box Plot)', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Grade', fontsize=12)\n",
    "    ax1.set_ylabel('Regional Price', fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Violin plot for detailed distribution\n",
    "    sns.violinplot(data=df_clean, x='Grade', y='Regional_Price', ax=ax2)\n",
    "    ax2.set_title('Price Distribution by Grade (Violin Plot)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Grade', fontsize=12)\n",
    "    ax2.set_ylabel('Regional Price', fontsize=12)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. Mean prices by grade with error bars\n",
    "    grade_stats = df_clean.groupby('Grade')['Regional_Price'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    grade_stats['se'] = grade_stats['std'] / np.sqrt(grade_stats['count'])\n",
    "    \n",
    "    ax3.bar(grade_stats['Grade'], grade_stats['mean'], \n",
    "            yerr=grade_stats['se'], capsize=5, alpha=0.7, color='skyblue', edgecolor='navy')\n",
    "    ax3.set_title('Average Price by Grade (with Standard Error)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Grade', fontsize=12)\n",
    "    ax3.set_ylabel('Average Regional Price', fontsize=12)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (grade, mean_price) in enumerate(zip(grade_stats['Grade'], grade_stats['mean'])):\n",
    "        ax3.text(i, mean_price + grade_stats['se'].iloc[i], f'{mean_price:.1f}', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 4. Histogram of all prices colored by grade\n",
    "    for grade in df_clean['Grade'].unique():\n",
    "        grade_data = df_clean[df_clean['Grade'] == grade]['Regional_Price']\n",
    "        ax4.hist(grade_data, alpha=0.6, label=grade, bins=20, density=True)\n",
    "    \n",
    "    ax4.set_title('Price Distribution Histograms by Grade', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Regional Price', fontsize=12)\n",
    "    ax4.set_ylabel('Density', fontsize=12)\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nPrice Distribution Summary by Grade:\")\n",
    "    print(\"=\" * 50)\n",
    "    summary_stats = df_clean.groupby('Grade')['Regional_Price'].describe()\n",
    "    print(summary_stats.round(2))\n",
    "\n",
    "plot_price_distribution_by_grade(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74382aa9",
   "metadata": {},
   "source": [
    "# 6.Visualization Function 2 - Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34beb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_correlation_matrix(df):\n",
    "    \"\"\"Plot feature correlation matrix\"\"\"\n",
    "    # Select numeric features for correlation analysis\n",
    "    numeric_features = [\n",
    "        'Regional_Price', 'National_Price', 'Seasonal_Impact',\n",
    "        'Local_Production_Volume', 'Local_Export_Volume',\n",
    "        'Global_Production_Volume', 'Global_Consumption_Volume',\n",
    "        'Temperature', 'Rainfall', 'Exchange_Rate', 'Inflation_Rate',\n",
    "        'Fuel_Price', 'Year', 'Month_num', 'Quarter', 'Grade_encoded',\n",
    "        'Region_encoded', 'Is_Active_Region','GRN_QTY'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only include columns that exist in the dataframe\n",
    "    available_features = [col for col in numeric_features if col in df.columns]\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    df_numeric = df[available_features].select_dtypes(include=[np.number])\n",
    "    correlation_matrix = df_numeric.corr()\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    \n",
    "    # Create a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                cmap='RdBu_r', \n",
    "                center=0,\n",
    "                fmt='.2f',\n",
    "                square=True,\n",
    "                cbar_kws={'label': 'Correlation Coefficient'},\n",
    "                annot_kws={'size': 8})\n",
    "    \n",
    "    plt.title('Feature Correlation Matrix\\n(Cinnamon Price Forecasting Dataset)', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Features', fontsize=12)\n",
    "    plt.ylabel('Features', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print highly correlated feature pairs\n",
    "    print(\"\\nHighly Correlated Feature Pairs (|correlation| > 0.7):\")\n",
    "    print(\"=\" * 60)\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_val = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    correlation_matrix.columns[i], \n",
    "                    correlation_matrix.columns[j], \n",
    "                    corr_val\n",
    "                ))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        for feature1, feature2, corr in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True):\n",
    "            print(f\"{feature1} ↔ {feature2}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"No feature pairs with |correlation| > 0.7 found.\")\n",
    "\n",
    "plot_feature_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff037f",
   "metadata": {},
   "source": [
    "# 7.Sequence Preparation Function for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(df, sequence_length=12, target_col='Regional_Price'):\n",
    "    \"\"\"Create sequences for LSTM training\"\"\"\n",
    "    feature_cols = [\n",
    "        'Grade_encoded', 'Region_encoded', 'Is_Active_Region',\n",
    "        'National_Price', 'Seasonal_Impact', 'Local_Production_Volume',\n",
    "        'Local_Export_Volume', 'Global_Production_Volume', 'Global_Consumption_Volume',\n",
    "        'Temperature', 'Rainfall', 'Exchange_Rate', 'Inflation_Rate', 'Fuel_Price',\n",
    "        'Year', 'Month_num', 'Quarter'\n",
    "    ]\n",
    "\n",
    "    # Add lag and rolling features\n",
    "    lag_cols = [col for col in df.columns if 'lag_' in col or 'rolling_' in col]\n",
    "    feature_cols.extend(lag_cols)\n",
    "\n",
    "    # Instead of dropping all NaNs, fill them\n",
    "    df_clean = df.copy()\n",
    "    df_clean = df_clean.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    X_sequences, y_sequences, metadata = [], [], []\n",
    "\n",
    "    for grade in df_clean['Grade'].unique():\n",
    "        for region in df_clean['Region'].unique():\n",
    "            subset = df_clean[(df_clean['Grade'] == grade) & (df_clean['Region'] == region)].sort_values('Month')\n",
    "\n",
    "            if len(subset) < sequence_length + 1:\n",
    "                continue\n",
    "\n",
    "            for i in range(len(subset) - sequence_length):\n",
    "                X_seq = subset.iloc[i:i + sequence_length][feature_cols].values\n",
    "                y_seq = subset.iloc[i + sequence_length][target_col]\n",
    "\n",
    "                X_sequences.append(X_seq)\n",
    "                y_sequences.append(y_seq)\n",
    "                metadata.append({\n",
    "                    'grade': grade,\n",
    "                    'region': region,\n",
    "                    'date': subset.iloc[i + sequence_length]['Month']\n",
    "                })\n",
    "\n",
    "    print(\"Total sequences created:\", len(X_sequences))\n",
    "    return np.array(X_sequences), np.array(y_sequences), metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fefbe1",
   "metadata": {},
   "source": [
    "# 8.LSTM Model Building with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model_tunable(units1=128, units2=64, dropout1=0.2, dropout2=0.2, \n",
    "                            dense_units=32, optimizer='adam', learning_rate=0.001, \n",
    "                            layer_type='LSTM', use_batch_norm=False, input_shape=None):\n",
    "    \"\"\"Build tunable LSTM model with various hyperparameters\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Choose layer type\n",
    "    if layer_type == 'LSTM':\n",
    "        model.add(LSTM(units1, return_sequences=True, input_shape=input_shape))\n",
    "    elif layer_type == 'GRU':\n",
    "        model.add(GRU(units1, return_sequences=True, input_shape=input_shape))\n",
    "    else:  # SimpleRNN\n",
    "        model.add(SimpleRNN(units1, return_sequences=True, input_shape=input_shape))\n",
    "    \n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dropout(dropout1))\n",
    "    \n",
    "    # Second RNN layer\n",
    "    if layer_type == 'LSTM':\n",
    "        model.add(LSTM(units2, return_sequences=False))\n",
    "    elif layer_type == 'GRU':\n",
    "        model.add(GRU(units2, return_sequences=False))\n",
    "    else:  # SimpleRNN\n",
    "        model.add(SimpleRNN(units2, return_sequences=False))\n",
    "    \n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "    model.add(Dropout(dropout2))\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Configure optimizer\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    else:  # SGD\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b7eda",
   "metadata": {},
   "source": [
    "# 9.Defining Tuner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterTuner:\n",
    "    \"\"\"Hyperparameter tuning class using multiple strategies\"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_val, y_val, input_shape):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.input_shape = input_shape\n",
    "        self.best_params = None\n",
    "        self.best_score = float('inf')\n",
    "        self.tuning_results = []\n",
    "    \n",
    "    def grid_search_tuning(self, param_grid=None, max_trials=20):\n",
    "        \"\"\"Grid search hyperparameter tuning\"\"\"\n",
    "        print(\"\\n🔍 Starting Grid Search Hyperparameter Tuning...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        if param_grid is None:\n",
    "            param_grid = {\n",
    "                'units1': [64, 128, 256, 512, 1024],\n",
    "                'units2': [32, 64, 128, 256, 512],\n",
    "                'dropout1': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                'dropout2': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                'dense_units': [16, 32, 64, 128, 256],\n",
    "                'learning_rate': [0.001, 0.0005, 0.002, 0.005, 0.01],\n",
    "                'layer_type': ['LSTM', 'GRU'],\n",
    "                'use_batch_norm': [True, False]\n",
    "            }\n",
    "        \n",
    "        # Generate all combinations and sample randomly if too many\n",
    "        param_combinations = list(product(*param_grid.values()))\n",
    "        if len(param_combinations) > max_trials:\n",
    "            param_combinations = np.random.choice(\n",
    "                param_combinations, size=max_trials, replace=False\n",
    "            )\n",
    "        \n",
    "        print(f\"Testing {len(param_combinations)} parameter combinations...\")\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_params = None\n",
    "        \n",
    "        for i, params in enumerate(param_combinations[:max_trials]):\n",
    "            param_dict = dict(zip(param_grid.keys(), params))\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nTrial {i+1}/{min(len(param_combinations), max_trials)}: {param_dict}\")\n",
    "                \n",
    "                # Build and train model\n",
    "                model = build_lstm_model_tunable(**param_dict, input_shape=self.input_shape)\n",
    "                \n",
    "                history = model.fit(\n",
    "                    self.X_train, self.y_train,\n",
    "                    validation_data=(self.X_val, self.y_val),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    verbose=0,\n",
    "                    callbacks=[\n",
    "                        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                        ReduceLROnPlateau(patience=3, factor=0.5, verbose=0)\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                val_loss = min(history.history['val_loss'])\n",
    "                \n",
    "                result = {\n",
    "                    'trial': i+1,\n",
    "                    'params': param_dict.copy(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_mae': min(history.history['val_mae'])\n",
    "                }\n",
    "                \n",
    "                self.tuning_results.append(result)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_params = param_dict.copy()\n",
    "                    print(f\"✅ New best validation loss: {val_loss:.6f}\")\n",
    "                else:\n",
    "                    print(f\"   Validation loss: {val_loss:.6f}\")\n",
    "                \n",
    "                # Clean up\n",
    "                del model\n",
    "                tf.keras.backend.clear_session()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Trial {i+1} failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        self.best_params = best_params\n",
    "        self.best_score = best_val_loss\n",
    "        \n",
    "        print(f\"\\n🎉 Grid Search Complete!\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        \n",
    "        return best_params, best_val_loss\n",
    "    \n",
    "    def optuna_tuning(self, n_trials=50):\n",
    "        \"\"\"Optuna-based hyperparameter tuning\"\"\"\n",
    "        print(\"\\n🎯 Starting Optuna Hyperparameter Tuning...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        def objective(trial):\n",
    "            # Define hyperparameter search space\n",
    "            params = {\n",
    "                'units1': trial.suggest_categorical('units1', [64, 128, 256, 512]),\n",
    "                'units2': trial.suggest_categorical('units2', [32, 64, 128, 256]),\n",
    "                'dropout1': trial.suggest_float('dropout1', 0.1, 0.5, step=0.1),\n",
    "                'dropout2': trial.suggest_float('dropout2', 0.1, 0.5, step=0.1),\n",
    "                'dense_units': trial.suggest_categorical('dense_units', [16, 32, 64, 128]),\n",
    "                'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-2),\n",
    "                'layer_type': trial.suggest_categorical('layer_type', ['LSTM', 'GRU']),\n",
    "                'use_batch_norm': trial.suggest_categorical('use_batch_norm', [True, False]),\n",
    "                'optimizer': trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                model = build_lstm_model_tunable(**params, input_shape=self.input_shape)\n",
    "                \n",
    "                history = model.fit(\n",
    "                    self.X_train, self.y_train,\n",
    "                    validation_data=(self.X_val, self.y_val),\n",
    "                    epochs=25,\n",
    "                    batch_size=32,\n",
    "                    verbose=0,\n",
    "                    callbacks=[\n",
    "                        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                        ReduceLROnPlateau(patience=3, factor=0.5, verbose=0)\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                val_loss = min(history.history['val_loss'])\n",
    "                \n",
    "                # Clean up\n",
    "                del model\n",
    "                tf.keras.backend.clear_session()\n",
    "                \n",
    "                return val_loss\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Trial failed: {e}\")\n",
    "                return float('inf')\n",
    "        \n",
    "        # Create study and optimize\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        self.best_params = study.best_params\n",
    "        self.best_score = study.best_value\n",
    "        \n",
    "        print(f\"\\n🎉 Optuna Tuning Complete!\")\n",
    "        print(f\"Best validation loss: {study.best_value:.6f}\")\n",
    "        print(f\"Best parameters: {study.best_params}\")\n",
    "        \n",
    "        # Plot optimization history\n",
    "        self.plot_optuna_results(study)\n",
    "        \n",
    "        return study.best_params, study.best_value\n",
    "    \n",
    "    def plot_optuna_results(self, study):\n",
    "        \"\"\"Plot Optuna optimization results\"\"\"\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Plot optimization history\n",
    "        trials = study.trials\n",
    "        values = [t.value for t in trials if t.value is not None]\n",
    "        ax1.plot(values, marker='o', alpha=0.7)\n",
    "        ax1.set_title('Optimization History', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Trial')\n",
    "        ax1.set_ylabel('Validation Loss')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot parameter importance\n",
    "        if len(study.trials) > 10:\n",
    "            try:\n",
    "                importance = optuna.importance.get_param_importances(study)\n",
    "                params = list(importance.keys())\n",
    "                importances = list(importance.values())\n",
    "                \n",
    "                ax2.barh(params, importances)\n",
    "                ax2.set_title('Parameter Importance', fontsize=14, fontweight='bold')\n",
    "                ax2.set_xlabel('Importance')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "            except:\n",
    "                ax2.text(0.5, 0.5, 'Parameter importance\\nnot available', \n",
    "                        ha='center', va='center', transform=ax2.transAxes)\n",
    "        \n",
    "        # Plot best value progression\n",
    "        best_values = []\n",
    "        current_best = float('inf')\n",
    "        for trial in study.trials:\n",
    "            if trial.value is not None and trial.value < current_best:\n",
    "                current_best = trial.value\n",
    "            best_values.append(current_best)\n",
    "        \n",
    "        ax3.plot(best_values, marker='o', alpha=0.7, color='green')\n",
    "        ax3.set_title('Best Value Progression', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Trial')\n",
    "        ax3.set_ylabel('Best Validation Loss')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Distribution of validation losses\n",
    "        ax4.hist(values, bins=20, alpha=0.7, edgecolor='black')\n",
    "        ax4.axvline(study.best_value, color='red', linestyle='--', \n",
    "                   label=f'Best: {study.best_value:.6f}')\n",
    "        ax4.set_title('Distribution of Validation Losses', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Validation Loss')\n",
    "        ax4.set_ylabel('Frequency')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def random_search_tuning(self, n_trials=30):\n",
    "        \"\"\"Random search hyperparameter tuning\"\"\"\n",
    "        print(\"\\n🎲 Starting Random Search Hyperparameter Tuning...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_params = None\n",
    "        \n",
    "        for i in range(n_trials):\n",
    "            # Randomly sample hyperparameters\n",
    "            params = {\n",
    "                'units1': np.random.choice([64, 128, 256, 512]),\n",
    "                'units2': np.random.choice([32, 64, 128, 256]),\n",
    "                'dropout1': np.random.uniform(0.1, 0.5),\n",
    "                'dropout2': np.random.uniform(0.1, 0.5),\n",
    "                'dense_units': np.random.choice([16, 32, 64, 128]),\n",
    "                'learning_rate': np.random.loguniform(1e-4, 1e-2),\n",
    "                'layer_type': np.random.choice(['LSTM', 'GRU']),\n",
    "                'use_batch_norm': np.random.choice([True, False]),\n",
    "                'optimizer': np.random.choice(['adam', 'rmsprop'])\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nTrial {i+1}/{n_trials}: {params}\")\n",
    "                \n",
    "                model = build_lstm_model_tunable(**params, input_shape=self.input_shape)\n",
    "                \n",
    "                history = model.fit(\n",
    "                    self.X_train, self.y_train,\n",
    "                    validation_data=(self.X_val, self.y_val),\n",
    "                    epochs=25,\n",
    "                    batch_size=32,\n",
    "                    verbose=0,\n",
    "                    callbacks=[\n",
    "                        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                        ReduceLROnPlateau(patience=3, factor=0.5, verbose=0)\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                val_loss = min(history.history['val_loss'])\n",
    "                \n",
    "                result = {\n",
    "                    'trial': i+1,\n",
    "                    'params': params.copy(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_mae': min(history.history['val_mae'])\n",
    "                }\n",
    "                \n",
    "                self.tuning_results.append(result)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_params = params.copy()\n",
    "                    print(f\"✅ New best validation loss: {val_loss:.6f}\")\n",
    "                else:\n",
    "                    print(f\"   Validation loss: {val_loss:.6f}\")\n",
    "                \n",
    "                # Clean up\n",
    "                del model\n",
    "                tf.keras.backend.clear_session()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Trial {i+1} failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        self.best_params = best_params\n",
    "        self.best_score = best_val_loss\n",
    "        \n",
    "        print(f\"\\n🎉 Random Search Complete!\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        \n",
    "        return best_params, best_val_loss\n",
    "    \n",
    "    def plot_tuning_results(self):\n",
    "        \"\"\"Plot hyperparameter tuning results\"\"\"\n",
    "        if not self.tuning_results:\n",
    "            print(\"No tuning results to plot.\")\n",
    "            return\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Extract data\n",
    "        trials = [r['trial'] for r in self.tuning_results]\n",
    "        val_losses = [r['val_loss'] for r in self.tuning_results]\n",
    "        val_maes = [r['val_mae'] for r in self.tuning_results]\n",
    "        \n",
    "        # Plot validation loss progression\n",
    "        ax1.plot(trials, val_losses, marker='o', alpha=0.7)\n",
    "        ax1.set_title('Validation Loss by Trial', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Trial')\n",
    "        ax1.set_ylabel('Validation Loss')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot validation MAE progression\n",
    "        ax2.plot(trials, val_maes, marker='s', alpha=0.7, color='orange')\n",
    "        ax2.set_title('Validation MAE by Trial', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Trial')\n",
    "        ax2.set_ylabel('Validation MAE')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Histogram of validation losses\n",
    "        ax3.hist(val_losses, bins=15, alpha=0.7, edgecolor='black')\n",
    "        ax3.axvline(self.best_score, color='red', linestyle='--', \n",
    "                   label=f'Best: {self.best_score:.6f}')\n",
    "        ax3.set_title('Distribution of Validation Losses', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Validation Loss')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Best value progression\n",
    "        best_so_far = []\n",
    "        current_best = float('inf')\n",
    "        for loss in val_losses:\n",
    "            if loss < current_best:\n",
    "                current_best = loss\n",
    "            best_so_far.append(current_best)\n",
    "        \n",
    "        ax4.plot(trials, best_so_far, marker='o', alpha=0.7, color='green')\n",
    "        ax4.set_title('Best Validation Loss Progression', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Trial')\n",
    "        ax4.set_ylabel('Best Validation Loss')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d877f",
   "metadata": {},
   "source": [
    "# 10.Perform Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperparameter_tuning(X_train, y_train, X_val, y_val, input_shape, \n",
    "                                 method='optuna', n_trials=30):\n",
    "    \"\"\"Main function to perform hyperparameter tuning\"\"\"\n",
    "    print(f\"\\n🚀 Starting Hyperparameter Tuning using {method.upper()} method...\")\n",
    "    \n",
    "    tuner = HyperparameterTuner(X_train, y_train, X_val, y_val, input_shape)\n",
    "    \n",
    "    if method == 'optuna':\n",
    "        best_params, best_score = tuner.optuna_tuning(n_trials=n_trials)\n",
    "    elif method == 'random':\n",
    "        best_params, best_score = tuner.random_search_tuning(n_trials=n_trials)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'optuna', 'grid', or 'random'\")\n",
    "    \n",
    "    # Plot results\n",
    "    if method in ['grid', 'random']:\n",
    "        tuner.plot_tuning_results()\n",
    "    \n",
    "    return best_params, best_score, tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5e06f",
   "metadata": {},
   "source": [
    "# 11. LSTM Model Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ac337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape, best_params=None):\n",
    "    \"\"\"Build LSTM model with optional best parameters from tuning\"\"\"\n",
    "    if best_params is None:\n",
    "        # Default parameters\n",
    "        best_params = {\n",
    "            'units1': 128,\n",
    "            'units2': 64,\n",
    "            'dropout1': 0.2,\n",
    "            'dropout2': 0.2,\n",
    "            'dense_units': 32,\n",
    "            'optimizer': 'adam',\n",
    "            'learning_rate': 0.001,\n",
    "            'layer_type': 'LSTM',\n",
    "            'use_batch_norm': False\n",
    "        }\n",
    "    \n",
    "    return build_lstm_model_tunable(**best_params, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f0f216",
   "metadata": {},
   "source": [
    "# 12. Training History Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training vs validation loss\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax1.plot(history.history['loss'], label='Training Loss', linewidth=2, color='blue')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2, color='red')\n",
    "    ax1.set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss (MSE)', fontsize=12)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training & validation MAE\n",
    "    ax2.plot(history.history['mae'], label='Training MAE', linewidth=2, color='blue')\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE', linewidth=2, color='red')\n",
    "    ax2.set_title('Model MAE Over Epochs', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('MAE', fontsize=12)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    final_train_mae = history.history['mae'][-1]\n",
    "    final_val_mae = history.history['val_mae'][-1]\n",
    "    \n",
    "    print(f\"\\nFinal Training Metrics:\")\n",
    "    print(f\"Training Loss: {final_train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"Training MAE: {final_train_mae:.4f}\")\n",
    "    print(f\"Validation MAE: {final_val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3782f",
   "metadata": {},
   "source": [
    "# 13.Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984947d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(df, use_tuning=True, tuning_method='optuna', n_tuning_trials=20):\n",
    "    \"\"\"Train the forecasting model with optional hyperparameter tuning\"\"\"\n",
    "    global scaler_features, scaler_target\n",
    "    \n",
    "    print(\"Preparing sequences...\")\n",
    "    X, y, metadata = prepare_sequences(df, SEQUENCE_LENGTH)\n",
    "\n",
    "    if len(X) == 0:\n",
    "        raise ValueError(\"No sequences could be created. Check if there's enough data.\")\n",
    "\n",
    "    print(f\"Created {len(X)} sequences with shape {X.shape}\")\n",
    "\n",
    "    # Scale features and target\n",
    "    print(\"Scaling features...\")\n",
    "    n_samples, n_timesteps, n_features = X.shape\n",
    "    X_reshaped = X.reshape(-1, n_features)\n",
    "    X_scaled_reshaped = scaler_features.fit_transform(X_reshaped)\n",
    "    X_scaled = X_scaled_reshaped.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "    y_scaled = scaler_target.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Train-validation-test split\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X_scaled, y_scaled, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42  # 0.25 * 0.8 = 0.2 of total\n",
    "    )\n",
    "\n",
    "    print(f\"Training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"Validation set shape: X={X_val.shape}, y={y_val.shape}\")\n",
    "    print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    best_params = None\n",
    "    tuner = None\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    if use_tuning:\n",
    "        print(f\"\\n🔧 Performing hyperparameter tuning using {tuning_method} method...\")\n",
    "        best_params, best_score, tuner = perform_hyperparameter_tuning(\n",
    "            X_train, y_train, X_val, y_val, input_shape, \n",
    "            method=tuning_method, n_trials=n_tuning_trials\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n📊 Hyperparameter Tuning Results:\")\n",
    "        print(f\"Best validation loss: {best_score:.6f}\")\n",
    "        print(f\"Best parameters:\")\n",
    "        for key, value in best_params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping hyperparameter tuning, using default parameters...\")\n",
    "\n",
    "    # Build and train final model with best parameters\n",
    "    print(\"\\nBuilding final model with optimized parameters...\")\n",
    "    model = build_lstm_model(input_shape, best_params)\n",
    "    \n",
    "    # Print model summary\n",
    "    print(\"\\n📋 Final Model Architecture:\")\n",
    "    model.summary()\n",
    "\n",
    "    print(\"\\nTraining final model...\")\n",
    "    \n",
    "    # Use longer training for final model\n",
    "    final_epochs = 150 if use_tuning else 100\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=final_epochs,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
    "            ReduceLROnPlateau(patience=8, factor=0.5, verbose=1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "\n",
    "    # Evaluate model on test set\n",
    "    print(\"\\nEvaluating final model on test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_unscaled = scaler_target.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "    y_test_unscaled = scaler_target.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    mae = mean_absolute_error(y_test_unscaled, y_pred_unscaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_unscaled))\n",
    "    r2 = r2_score(y_test_unscaled, y_pred_unscaled)\n",
    "\n",
    "    print(f\"\\n🎯 Final Model Performance on Test Set:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    \n",
    "    # Create comprehensive results dictionary\n",
    "    results = {\n",
    "        'mae': mae, \n",
    "        'rmse': rmse, \n",
    "        'r2': r2,\n",
    "        'best_params': best_params,\n",
    "        'tuning_method': tuning_method if use_tuning else None,\n",
    "        'tuning_used': use_tuning,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'final_train_loss': history.history['loss'][-1],\n",
    "        'final_val_loss': history.history['val_loss'][-1]\n",
    "    }\n",
    "    \n",
    "    # Add tuning results if available\n",
    "    if tuner and hasattr(tuner, 'tuning_results'):\n",
    "        results['tuning_results'] = tuner.tuning_results\n",
    "    \n",
    "    return model, history, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a079536a",
   "metadata": {},
   "source": [
    "# 14.Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f083092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with hyperparameter tuning\n",
    "print(\"🚀 STARTING MODEL TRAINING WITH HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# You can change these parameters:\n",
    "USE_HYPERPARAMETER_TUNING = True  # Set to False to skip tuning\n",
    "TUNING_METHOD = 'optuna'  # Options: 'optuna', 'grid', 'random'\n",
    "N_TUNING_TRIALS = 50  # Number of trials for tuning\n",
    "\n",
    "model, history, metrics = train_model(\n",
    "    df, \n",
    "    use_tuning=USE_HYPERPARAMETER_TUNING,\n",
    "    tuning_method=TUNING_METHOD,\n",
    "    n_tuning_trials=N_TUNING_TRIALS\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811df18b",
   "metadata": {},
   "source": [
    "# 15.Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, metrics, model_dir=MODEL_DIR):\n",
    "    \"\"\"Save the trained model and all preprocessors\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create model-specific directory\n",
    "    model_save_dir = os.path.join(model_dir, f\"cinnamon_model_{timestamp}\")\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n📁 Saving model to: {model_save_dir}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Save the Keras model\n",
    "        model_path = os.path.join(model_save_dir, \"lstm_model.keras\")\n",
    "        model.save(model_path)\n",
    "        print(f\"✅ Keras model saved: lstm_model.keras\")\n",
    "        \n",
    "        # 2. Save scalers\n",
    "        scalers_path = os.path.join(model_save_dir, \"scalers.pkl\")\n",
    "        scalers = {\n",
    "            'scaler_features': scaler_features,\n",
    "            'scaler_target': scaler_target\n",
    "        }\n",
    "        with open(scalers_path, 'wb') as f:\n",
    "            pickle.dump(scalers, f)\n",
    "        print(f\"✅ Scalers saved: scalers.pkl\")\n",
    "        \n",
    "        # 3. Save label encoders\n",
    "        encoders_path = os.path.join(model_save_dir, \"label_encoders.pkl\")\n",
    "        with open(encoders_path, 'wb') as f:\n",
    "            pickle.dump(label_encoders, f)\n",
    "        print(f\"✅ Label encoders saved: label_encoders.pkl\")\n",
    "        \n",
    "        # 4. Save model configuration and metadata (enhanced with tuning info)\n",
    "        config = {\n",
    "            'sequence_length': SEQUENCE_LENGTH,\n",
    "            'model_architecture': {\n",
    "                'input_shape': model.input_shape,\n",
    "                'layers': [str(layer.__class__.__name__) for layer in model.layers],\n",
    "                'total_params': model.count_params()\n",
    "            },\n",
    "            'training_info': {\n",
    "                'timestamp': timestamp,\n",
    "                'mae': float(metrics['mae']),\n",
    "                'rmse': float(metrics['rmse']),\n",
    "                'r2': float(metrics['r2']),\n",
    "                'tuning_used': metrics.get('tuning_used', False),\n",
    "                'tuning_method': metrics.get('tuning_method', None),\n",
    "                'best_params': metrics.get('best_params', None),\n",
    "                'epochs_trained': metrics.get('epochs_trained', 0),\n",
    "                'final_train_loss': float(metrics.get('final_train_loss', 0)),\n",
    "                'final_val_loss': float(metrics.get('final_val_loss', 0))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save tuning results if available\n",
    "        if 'tuning_results' in metrics and metrics['tuning_results']:\n",
    "            tuning_results_path = os.path.join(model_save_dir, \"tuning_results.json\")\n",
    "            with open(tuning_results_path, 'w') as f:\n",
    "                json.dump(metrics['tuning_results'], f, indent=2, default=str)\n",
    "            print(f\"✅ Hyperparameter tuning results saved: tuning_results.json\")\n",
    "        \n",
    "        config_path = os.path.join(model_save_dir, \"model_config.json\")\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=2, default=str)\n",
    "        print(f\"✅ Model configuration saved: model_config.json\")\n",
    "        \n",
    "        print(f\"\\n🎉 Model successfully saved to: {model_save_dir}\")\n",
    "        \n",
    "        # Print summary of saved model\n",
    "        print(f\"\\n📊 Saved Model Summary:\")\n",
    "        print(f\"  • Performance: MAE={metrics['mae']:.2f}, RMSE={metrics['rmse']:.2f}, R²={metrics['r2']:.4f}\")\n",
    "        if metrics.get('tuning_used'):\n",
    "            print(f\"  • Hyperparameter tuning: {metrics['tuning_method']} method used\")\n",
    "            print(f\"  • Best parameters found and applied\")\n",
    "        print(f\"  • Training epochs: {metrics.get('epochs_trained', 'N/A')}\")\n",
    "        print(f\"  • Total parameters: {model.count_params():,}\")\n",
    "        \n",
    "        return model_save_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_saved_model(model_path):\n",
    "    \"\"\"Load a previously saved model and preprocessors\"\"\"\n",
    "    global scaler_features, scaler_target, label_encoders\n",
    "    \n",
    "    print(f\"📂 Loading model from: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load the Keras model\n",
    "        keras_model_path = os.path.join(model_path, \"lstm_model.keras\")\n",
    "        model = load_model(keras_model_path)\n",
    "        print(f\"✅ Keras model loaded\")\n",
    "        \n",
    "        # Load scalers\n",
    "        scalers_path = os.path.join(model_path, \"scalers.pkl\")\n",
    "        with open(scalers_path, 'rb') as f:\n",
    "            scalers = pickle.load(f)\n",
    "        scaler_features = scalers['scaler_features']\n",
    "        scaler_target = scalers['scaler_target']\n",
    "        print(f\"✅ Scalers loaded\")\n",
    "        \n",
    "        # Load label encoders\n",
    "        encoders_path = os.path.join(model_path, \"label_encoders.pkl\")\n",
    "        with open(encoders_path, 'rb') as f:\n",
    "            label_encoders = pickle.load(f)\n",
    "        print(f\"✅ Label encoders loaded\")\n",
    "        \n",
    "        # Load configuration\n",
    "        config_path = os.path.join(model_path, \"model_config.json\")\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        print(f\"🎉 Model successfully loaded!\")\n",
    "        print(f\"📊 Performance: MAE={config['training_info']['mae']:.2f}, \"\n",
    "              f\"RMSE={config['training_info']['rmse']:.2f}, \"\n",
    "              f\"R²={config['training_info']['r2']:.4f}\")\n",
    "        \n",
    "        if config['training_info'].get('tuning_used'):\n",
    "            print(f\"🔧 This model was trained with {config['training_info']['tuning_method']} hyperparameter tuning\")\n",
    "        \n",
    "        return model, config\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading model: {str(e)}\")\n",
    "        return None, None\n",
    "    \n",
    "saved_model_path=save_model(model, metrics)\n",
    "print(f\"Model saved at: {saved_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9824a7",
   "metadata": {},
   "source": [
    "# 16.Define Train Features Globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FEATURE_COLS = [\n",
    "    'Grade_encoded', 'Region_encoded', 'Is_Active_Region',\n",
    "    'National_Price', 'Seasonal_Impact', 'Local_Production_Volume',\n",
    "    'Local_Export_Volume', 'Global_Production_Volume', 'Global_Consumption_Volume',\n",
    "    'Temperature', 'Rainfall', 'Exchange_Rate', 'Inflation_Rate', 'Fuel_Price',\n",
    "    'Year', 'Month_num', 'Quarter',\n",
    "    'Regional_Price_lag_1', 'Regional_Price_lag_3', 'Regional_Price_lag_6', 'Regional_Price_lag_12',\n",
    "    'National_Price_lag_1', 'National_Price_lag_3', 'National_Price_lag_6', 'National_Price_lag_12',\n",
    "    'Temperature_lag_1', 'Temperature_lag_3', 'Temperature_lag_6', 'Temperature_lag_12',\n",
    "    'Rainfall_lag_1', 'Rainfall_lag_3', 'Rainfall_lag_6', 'Rainfall_lag_12',\n",
    "    'Regional_Price_rolling_3', 'Regional_Price_rolling_6', 'Regional_Price_rolling_12',\n",
    "    'Temperature_rolling_3', 'Temperature_rolling_6', 'Temperature_rolling_12',\n",
    "    'Rainfall_rolling_3', 'Rainfall_rolling_6', 'Rainfall_rolling_12'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4d566",
   "metadata": {},
   "source": [
    "# 17. Forecasting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_prices(model, df, grade, region, months_ahead=12):\n",
    "    subset = df[(df['Grade'] == grade) & (df['Region'] == region)].sort_values('Month')\n",
    "    last_row = subset.iloc[-1]\n",
    "    last_date = last_row['Month']\n",
    "\n",
    "    future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1),\n",
    "                                 periods=months_ahead, freq='MS')\n",
    "    \n",
    "    # Generate future rows\n",
    "    future_rows = []\n",
    "    for future_date in future_dates:\n",
    "        row = last_row.copy()\n",
    "        row['Month'] = future_date\n",
    "        row['Year'] = future_date.year\n",
    "        row['Month_num'] = future_date.month\n",
    "        row['Quarter'] = future_date.quarter\n",
    "        row['Temperature'] = last_row['Temperature'] + 2 * np.sin(2*np.pi*(future_date.month-1)/12) + np.random.normal(0,0.5)\n",
    "        row['Rainfall'] = max(0, last_row['Rainfall'] + 20 * np.sin(2*np.pi*(future_date.month-1)/12) + np.random.normal(0,10))\n",
    "        row['Exchange_Rate'] = last_row['Exchange_Rate'] * (1 + np.random.normal(0.001,0.005))\n",
    "        row['Inflation_Rate'] = last_row['Inflation_Rate'] + np.random.normal(0,0.1)\n",
    "        row['Fuel_Price'] = last_row['Fuel_Price'] * (1 + np.random.normal(0.002,0.02))\n",
    "        future_rows.append(row)\n",
    "\n",
    "    future_df = pd.DataFrame(future_rows)\n",
    "    extended_df = pd.concat([subset, future_df], ignore_index=True).sort_values('Month')\n",
    "\n",
    "    # Recreate lag and rolling features\n",
    "    for col in ['Regional_Price','National_Price','Temperature','Rainfall']:\n",
    "        for lag in [1,3,6,12]:\n",
    "            extended_df[f'{col}_lag_{lag}'] = extended_df.groupby(['Grade','Region'])[col].shift(lag)\n",
    "        for window in [3,6,12]:\n",
    "            extended_df[f'{col}_rolling_{window}'] = extended_df.groupby(['Grade','Region'])[col].transform(lambda x: x.rolling(window).mean())\n",
    "\n",
    "    # Select exactly the features used during training\n",
    "    feature_cols = [c for c in TRAIN_FEATURE_COLS if c in extended_df.columns]\n",
    "\n",
    "    forecasts = []\n",
    "    historical_data = extended_df[extended_df['Month'] <= last_date]\n",
    "\n",
    "    for i in range(months_ahead):\n",
    "        current_data = extended_df.iloc[len(historical_data)-SEQUENCE_LENGTH+i : len(historical_data)+i]\n",
    "        if len(current_data) < SEQUENCE_LENGTH:\n",
    "            padding_needed = SEQUENCE_LENGTH - len(current_data)\n",
    "            last_known = historical_data.iloc[-1:].copy()\n",
    "            padding_data = pd.concat([last_known]*padding_needed, ignore_index=True)\n",
    "            current_data = pd.concat([padding_data, current_data], ignore_index=True).iloc[-SEQUENCE_LENGTH:]\n",
    "\n",
    "        sequence = current_data[feature_cols].ffill().bfill().values\n",
    "        sequence_flat = sequence.reshape(-1, sequence.shape[-1])\n",
    "        sequence_scaled_flat = scaler_features.transform(sequence_flat)\n",
    "        sequence_scaled = sequence_scaled_flat.reshape(sequence.shape)\n",
    "\n",
    "        next_pred = model.predict(sequence_scaled.reshape(1, SEQUENCE_LENGTH, -1), verbose=0)\n",
    "        next_pred_unscaled = scaler_target.inverse_transform(next_pred)[0][0]\n",
    "        forecasts.append(next_pred_unscaled)\n",
    "\n",
    "        future_idx = len(historical_data)+i\n",
    "        extended_df.iloc[future_idx, extended_df.columns.get_loc('Regional_Price')] = next_pred_unscaled\n",
    "        extended_df.iloc[future_idx, extended_df.columns.get_loc('National_Price')] = next_pred_unscaled\n",
    "\n",
    "    return forecasts, future_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852f9ac",
   "metadata": {},
   "source": [
    "# 18. Forecast Visulaization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_results(df, model, grade, region, months_ahead=12):\n",
    "    \"\"\"Plot 2: Historical data with forecast results\"\"\"\n",
    "    try:\n",
    "        # Get historical data for the specific grade and region\n",
    "        subset = df[(df['Grade'] == grade) & (df['Region'] == region)].sort_values('Month')\n",
    "        \n",
    "        if len(subset) == 0:\n",
    "            print(f\"No data found for {grade} in {region}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts, future_dates = forecast_prices(model, df, grade, region, months_ahead)\n",
    "        \n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        \n",
    "        # Plot historical data\n",
    "        plt.plot(subset['Month'], subset['Regional_Price'], \n",
    "                label='Historical Prices', linewidth=2, color='blue', marker='o', markersize=4)\n",
    "        \n",
    "        # CREATE BRIDGE: Connect last historical point to first forecast\n",
    "        last_historical_date = subset['Month'].iloc[-1]\n",
    "        last_historical_price = subset['Regional_Price'].iloc[-1]\n",
    "        first_forecast_date = future_dates[0]\n",
    "        first_forecast_price = forecasts[0]\n",
    "        \n",
    "        # Plot the connecting line (bridge)\n",
    "        plt.plot([last_historical_date, first_forecast_date], \n",
    "                [last_historical_price, first_forecast_price], \n",
    "                color='orange', linewidth=2, linestyle='-', alpha=0.8, \n",
    "                label='Historical-Forecast Bridge')\n",
    "        \n",
    "        # Plot forecasts (connected line)\n",
    "        extended_forecast_dates = [last_historical_date] + list(future_dates)\n",
    "        extended_forecasts = [last_historical_price] + list(forecasts)\n",
    "        \n",
    "        plt.plot(extended_forecast_dates, extended_forecasts, \n",
    "                label='Forecasted Prices', linewidth=2, color='red', \n",
    "                marker='s', markersize=5, linestyle='--', alpha=0.9)\n",
    "        \n",
    "        # Add a vertical line to separate historical and forecasted data\n",
    "        plt.axvline(x=last_historical_date, color='blue', linestyle=':', alpha=0.5, linewidth=1, \n",
    "                   label='Forecast Start')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title(f'Cinnamon Price Forecast: {grade.title()} Grade in {region.title()}\\n'\n",
    "                 f'Historical Data vs {months_ahead}-Month Forecast', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('Regional Price', fontsize=12)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Format x-axis dates\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add confidence bands (simplified approach using standard deviation)\n",
    "        if len(forecasts) > 1:\n",
    "            forecast_std = np.std(subset['Regional_Price'].tail(12))  # Use last 12 months std\n",
    "            upper_bound = np.array(extended_forecasts[1:]) + 1.96 * forecast_std  # Exclude bridge point\n",
    "            lower_bound = np.array(extended_forecasts[1:]) - 1.96 * forecast_std\n",
    "            \n",
    "            plt.fill_between(future_dates, lower_bound, upper_bound, \n",
    "                           alpha=0.2, color='red', label='95% Confidence Interval')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print forecast summary\n",
    "        print(f\"\\n{grade.title()} Grade Forecast for {region.title()}:\")\n",
    "        print(\"=\" * 50)\n",
    "        for i, (date, price) in enumerate(zip(future_dates, forecasts), 1):\n",
    "            print(f\"Month {i:2d} ({date.strftime('%Y-%m')}): LKR.{price:8.2f}\")\n",
    "        \n",
    "        print(f\"\\nForecast Statistics:\")\n",
    "        print(f\"Average Forecast Price: LKR.{np.mean(forecasts):.2f}\")\n",
    "        print(f\"Price Range: LKR.{np.min(forecasts):.2f} - LKR.{np.max(forecasts):.2f}\")\n",
    "        \n",
    "        # Calculate trend\n",
    "        if len(forecasts) > 1:\n",
    "            trend = (forecasts[-1] - forecasts[0]) / len(forecasts)\n",
    "            trend_direction = \"increasing\" if trend > 0 else \"decreasing\"\n",
    "            print(f\"Overall Trend: {trend_direction} by LKR.{abs(trend):.2f} per month\")\n",
    "        \n",
    "        return forecasts, future_dates\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting forecast results: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b68525",
   "metadata": {},
   "source": [
    "# 19.Generate Forecast Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820aeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_grades = df['Grade'].unique()\n",
    "available_regions = df['Region'].unique()\n",
    "\n",
    "print(f\"Available grades: {available_grades}\")\n",
    "print(f\"Available regions: {available_regions}\")\n",
    "\n",
    "# Generate forecast for first combination\n",
    "if len(available_grades) > 0 and len(available_regions) > 0:\n",
    "    grade_to_forecast = available_grades[0]\n",
    "    region_to_forecast = available_regions[0]\n",
    "    \n",
    "    print(f\"\\n📈 Generating forecast for {grade_to_forecast} in {region_to_forecast}...\")\n",
    "    forecasts1, future_dates1 = plot_forecast_results(\n",
    "        df, model, grade_to_forecast, region_to_forecast, months_ahead=6\n",
    "    )\n",
    "\n",
    "# Try another combination if available\n",
    "if len(available_grades) > 1 and len(available_regions) > 1:\n",
    "    grade_to_forecast2 = available_grades[1] if len(available_grades) > 1 else available_grades[0]\n",
    "    region_to_forecast2 = available_regions[1] if len(available_regions) > 1 else available_regions[0]\n",
    "    \n",
    "    print(f\"\\n📈 Generating forecast for {grade_to_forecast2} in {region_to_forecast2}...\")\n",
    "    forecasts2, future_dates2 = plot_forecast_results(\n",
    "        df, model, grade_to_forecast2, region_to_forecast2, months_ahead=6\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caca407",
   "metadata": {},
   "source": [
    "# 20. Interactive Forecast Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e188d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_forecast():\n",
    "    \"\"\"Allow user to select grade and region for forecasting\"\"\"\n",
    "    print(\"\\n🔮 Interactive Forecast Generation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display available options\n",
    "    print(\"\\nAvailable Grades:\")\n",
    "    for i, grade in enumerate(available_grades, 1):\n",
    "        print(f\"{i}. {grade}\")\n",
    "    \n",
    "    print(\"\\nAvailable Regions:\")\n",
    "    for i, region in enumerate(available_regions, 1):\n",
    "        print(f\"{i}. {region}\")\n",
    "    \n",
    "    # Get user input\n",
    "    try:\n",
    "        grade_idx = int(input(\"\\nSelect grade number: \")) - 1\n",
    "        region_idx = int(input(\"Select region number: \")) - 1\n",
    "        months = int(input(\"How many months to forecast (default 6): \") or \"6\")\n",
    "        \n",
    "        if 0 <= grade_idx < len(available_grades) and 0 <= region_idx < len(available_regions):\n",
    "            selected_grade = available_grades[grade_idx]\n",
    "            selected_region = available_regions[region_idx]\n",
    "            \n",
    "            print(f\"\\n📊 Generating {months}-month forecast for {selected_grade} in {selected_region}...\")\n",
    "            forecasts, dates = plot_forecast_results(\n",
    "                df, model, selected_grade, selected_region, months_ahead=months\n",
    "            )\n",
    "            return forecasts, dates\n",
    "        else:\n",
    "            print(\"Invalid selection. Please try again.\")\n",
    "            return None, None\n",
    "            \n",
    "    except (ValueError, IndexError) as e:\n",
    "        print(f\"Error: {e}. Please enter valid numbers.\")\n",
    "        return None, None\n",
    "\n",
    "interactive_forecast()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb6fcb",
   "metadata": {},
   "source": [
    "# 21.Hyperparameter Tuning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 HYPERPARAMETER TUNING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if metrics.get('tuning_used'):\n",
    "    print(f\"✅ Hyperparameter tuning was performed using: {metrics['tuning_method']}\")\n",
    "    print(f\"🏆 Best parameters found:\")\n",
    "    for key, value in metrics['best_params'].items():\n",
    "        print(f\"   • {key}: {value}\")\n",
    "    print(f\"\\n📊 Final Model Performance:\")\n",
    "    print(f\"   • MAE: {metrics['mae']:.4f}\")\n",
    "    print(f\"   • RMSE: {metrics['rmse']:.4f}\")\n",
    "    print(f\"   • R²: {metrics['r2']:.4f}\")\n",
    "    print(f\"   • Training epochs: {metrics['epochs_trained']}\")\n",
    "else:\n",
    "    print(\"❌ Hyperparameter tuning was skipped - default parameters used\")\n",
    "\n",
    "print(\"\\n💡 To use different tuning methods, modify these variables:\")\n",
    "print(\"   • USE_HYPERPARAMETER_TUNING = True/False\")\n",
    "print(\"   • TUNING_METHOD = 'optuna'/'grid'/'random'\")  \n",
    "print(\"   • N_TUNING_TRIALS = number of trials\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
